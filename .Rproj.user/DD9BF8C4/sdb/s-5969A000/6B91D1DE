{
    "collab_server" : "",
    "contents" : "### Utils from https://github.com/reptalex/COVID_ERL, with modified outlier detection\n\n\n### These tools were used in the following papers:\n## Analysis of COVID outbreaks on a timescale of burden:\n## https://www.medrxiv.org/content/10.1101/2021.05.03.21256542v2\n\n## Characaterizing features of outbreak duration for novel SARS-CoV-2 variants of concern\n## https://www.medrxiv.org/content/10.1101/2022.01.14.22269288v1\n\n\nlibrary(data.table)\nlibrary(deSolve)\nlibrary(magrittr)\nlibrary(zoo)\nlibrary(KFAS)\nlibrary(parallel)\nlibrary(tidyverse)\nlibrary(tsoutliers)\nlibrary(progress)\nlibrary(lubridate)\nlibrary(EpiEstim)\nlibrary(mgcv)\n\ndfs <- function(x){\n  x <- c(x[1],diff(x))\n  x[x<0] <- NA\n  return(x)\n}\n\n# Requires to get sockets parallization to work on os x. \nlibrary(rstudioapi)\nif (Sys.getenv(\"RSTUDIO\") == \"1\" && !nzchar(Sys.getenv(\"RSTUDIO_TERM\")) && \n    Sys.info()[\"sysname\"] == \"Darwin\" && getRversion() >= \"4.0.0\") {\n  if(versionInfo()$version < \"1.3.1056\"){\n    parallel:::setDefaultClusterOptions(setup_strategy = \"sequential\")\n  }  \n}\n\nnbs <- function(x,name='growth_rate',seasonal=TRUE,remove_initial_zeros=TRUE,...){\n  y <- rep(NA,length(x))\n  if (remove_initial_zeros){\n    first_nz <- min(which(x>0))\n  } else {\n    first_nz <- 1\n  }\n  \n  if (name=='all'){\n    mdl <- nbss(x[first_nz:length(x)],...)\n    \n    dd <- matrix(NA,nrow=first_nz-1,ncol=ncol(mdl))\n    colnames(dd) <- colnames(mdl)\n    y <- rbind(dd,mdl)\n  } else {\n    y[first_nz:length(x)] <- nbss(x[first_nz:length(x)],...)  %>% getElement(name)\n  }\n  return(y)\n}\n\nnbss <- function(x,filtering=FALSE,seasonal=TRUE,dispersion=NULL){\n  if (seasonal){\n    nb_model <- function(x, pars){\n      model_nb <- SSModel(x ~ SSMtrend(2, Q=list(0, NA),\n                                       P1=diag(c(10, 1)),\n                                       a1=c(0, 0),\n                                       state_names=c(\"level\", \"trend\"))+\n                            SSMseasonal(7),\n                          u=rep(exp(pars[1]), length(x)), distribution=\"negative binomial\")\n      fit <- fitSSM(model_nb, c(0), method=\"L-BFGS-B\", control=list(maxit=200))\n      return(fit)\n    }\n  } else {\n    nb_model <- function(x, pars){\n      model_nb <- SSModel(x ~ SSMtrend(2, Q=list(0, NA),\n                                       P1=diag(c(10, 1)),\n                                       a1=c(0, 0),\n                                       state_names=c(\"level\", \"trend\")),\n                          u=rep(exp(pars[1]), length(x)), distribution=\"negative binomial\")\n      fit <- fitSSM(model_nb, c(0), method=\"L-BFGS-B\", control=list(maxit=200))\n      return(fit)\n    }\n  }\n  \n  if (is.null(dispersion)){\n    logLik_nb <- function(x, pars){\n      fit <- nb_model(x, pars)\n      ll <- logLik(fit$model, marginal = TRUE)\n      return(-ll)\n    }\n    \n    res <- tryCatch(optim(c(-1), function(y) logLik_nb(x, y), method=\"Brent\", lower=-2, upper=2) , error=function(e) NULL)\n    if (is.null(res)) return(NULL)\n    fit <- nb_model(x, res$par)\n  } else {\n    fit <- tryCatch(nb_model(x,dispersion),error=function(e) NULL)\n    res <- NULL\n    res$par[1] <- dispersion\n  }\n  if (filtering==TRUE){\n    sm_signal <- KFS(fit$model, filtering=\"signal\",smoothing='none')\n    sm_state <- KFS(fit$model, filtering=\"state\",smoothing='none')\n    \n    out <- data.frame(p2.5_position = c(qnorm(0.025, sm_state$a[-1,'level'], (sqrt(sm_state$P[1,1,-1])))), \n                      p97.5_position = c(qnorm(0.975, sm_state$a[-1,'level'],(sqrt(sm_state$P[1,1,-1])))), \n                      mean_position = (c(sm_state$a[-1,'level'])),\n                      p2.5_growth_rate = c(qnorm(0.025, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                      p97.5_growth_rate = c(qnorm(0.975, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))),\n                      p25_growth_rate = c(qnorm(0.25, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                      p75_growth_rate = c(qnorm(0.75, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                      growth_rate = (c(sm_state$a[-1,'trend'])),\n                      percentile_0_growth_rate =c(pnorm(0, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))),\n                      growth_rate = (c(sm_state$a[-1,'trend'])),\n                      dispersion=res$par[1], \n                      z_score_growth_rate = c(sm_state$a[-1,2]/sqrt(sm_state$P[2,2,-1])))\n  } else {\n    sm_signal <- KFS(fit$model, smoothing=\"signal\")\n    sm_state <- KFS(fit$model, smoothing=\"state\")\n    out <- data.frame(p2.5_signal = exp(qnorm(0.025, sm_signal$thetahat, sqrt(c(sm_signal$V_theta)))), \n                      p97.5_signal = exp(qnorm(0.975, sm_signal$thetahat, sqrt(c(sm_signal$V_theta)))), \n                      mean_signal = exp(sm_signal$thetahat), \n                      p2.5_position = c(qnorm(0.025, sm_state$alphahat[,1], (sqrt(sm_state$V[1,1,])))), \n                      p97.5_position = c(qnorm(0.975, sm_state$alphahat[,1],(sqrt(sm_state$V[1,1,])))), \n                      mean_position = (c(sm_state$alphahat[,1])),\n                      p2.5_growth_rate = c(qnorm(0.025, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                      p97.5_growth_rate = c(qnorm(0.975, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))),\n                      p25_growth_rate = c(qnorm(0.25, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                      p75_growth_rate = c(qnorm(0.75, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                      growth_rate = (c(sm_state$alphahat[,2])),\n                      percentile_0_growth_rate =c(pnorm(0, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))),\n                      growth_rate = (c(sm_state$alphahat[,2])),\n                      dispersion=res$par[1], \n                      z_score_growth_rate = c(sm_state$alphahat[,2]/sqrt(sm_state$V[2,2,])))\n  }\n  return(out)\n}\n\n\nfit_covid_ssm <- function(d, series=\"new_confirmed\", precomputed_dispersions=NULL,\n                          return_fit=FALSE,maxiter=200,filtering=FALSE){\n  dat <- d\n  \n  # Helper functions\n  nb_model <- function(dat, pars){\n    model_nb <- SSModel(dat[,series] ~ SSMtrend(2, Q=list(0, NA),\n                                                     P1=diag(c(10, 1)),\n                                                     a1=c(0, 0),\n                                                     state_names=c(\"level\", \"trend\"))+\n                          SSMseasonal(7),\n                        u=rep(exp(pars[1]), nrow(dat)), distribution=\"negative binomial\")\n    fit <- fitSSM(model_nb, c(0), method=\"L-BFGS-B\", control=list(maxit=200))\n    return(fit)\n  }\n  logLik_nb <- function(dat, pars){\n    fit <- nb_model(dat, pars)\n    ll <- logLik(fit$model, marginal = TRUE)\n    return(-ll)\n  }\n  \n  # Remove preceding zeros\n  dat <- dat %>% \n    arrange(date)\n  dat$cs = cumsum(ifelse(is.na(dat[,series]), 0, dat[,series]))\n  pass <- dat$cs > 0 # rows to keep in analysis \n  # dat <- dat %>% filter(cs > 0)\n  \n  \n  if (nrow(dat[pass,]) < 10) return(cbind(d, error=\"not enough non-zero\"))\n  \n  \n  # Remove weekend zeros\n  dat[[series]] <- ifelse((dat[[series]] == 0) & (format(dat$date, \"%u\") %in% c(6,7)), \n                          NA, dat[[series]])\n  # Remove holiday zeros\n  dat[[series]] <- ifelse((dat[[series]] == 0) & (dat$date %in% c(ymd(\"2020-11-26\"), # Thanksgiving\n                                                                  ymd(\"2020-12-25\"), \n                                                                  ymd(\"2020-12-31\"), \n                                                                  ymd(\"2021-01-01\"))),\n                          NA, dat[[series]])\n  \n  \n  # outlier detection for early outbreak\n  pass <- custom_processors(dat, pass)\n  if (sum(dat[pass,series]!=0, na.rm=TRUE) < 10) return(cbind(d, error=\"not enough non-zero\"))\n  tryCatch({\n    tmp <-getElement(dat,series)[pass]\n    #tmp <- ifelse(is.na(tmp), 0, tmp)\n    tmp <- na.approx(tmp)\n    outlier_filtered_ts <- tmp %>% outlier_detection\n    outlier_filtered_ts[is.na(getElement(dat, series)[pass])] <- NA\n    tmp <- rep(NA, nrow(dat))\n    tmp[pass] <- outlier_filtered_ts\n    dat <- mutate(dat, series=tmp)    \n  },  error = function(err){\n    return(cbind(d, error=\"outlier detection errored\"))\n  })\n  \n  if (length(dat[pass,series][!is.na(dat[pass,series])]) < 10) return(cbind(d, error=\"too many NA\"))\n  \n  \n  if (!is.null(precomputed_dispersions)){\n    res <- list()\n    res$par <- dplyr::filter(precomputed_dispersions, id==unique(dat$id))$dispersion\n    if (length(res$par)==0) return(cbind(d, error=\"could not find precomputed dispersions\")) # no precomputed dispersion (previously was not able to fit likely)\n  } else {\n    res <- tryCatch(optim(c(-1), function(x) logLik_nb(dat[pass,], x), method=\"Brent\", lower=-2, upper=3), \n                    error = function(e) NULL)\n    if (is.null(res)) return(cbind(d, error=\"dispersion optimization failed\"))\n    if (res$convergence != 0) return(cbind(d, error=\"dispersion optimization failed\"))\n  }\n  \n  # now fit the model with the optimized dispersion parameters\n  fit <- tryCatch(nb_model(dat[pass,], res$par),error=function(e) NA)\n  if (is.na(fit)){\n    return(NULL)\n  } else {\n    if(return_fit) return(fit)\n    if (fit$optim.out$convergence != 0) return(cbind(d, error=\"model optimiztion (not dispersion) failed\"))\n    if (filtering==FALSE){\n      sm_signal <- KFS(fit$model, smoothing=\"signal\")\n      sm_state <- KFS(fit$model, smoothing=\"state\")\n      \n      if (series==\"new_confirmed\"){\n        out <- data.frame(p2.5_signal = exp(qnorm(0.025, sm_signal$thetahat, sqrt(c(sm_signal$V_theta)))), \n                          p97.5_signal = exp(qnorm(0.975, sm_signal$thetahat, sqrt(c(sm_signal$V_theta)))), \n                          mean_signal = exp(sm_signal$thetahat), \n                          p2.5_position = c(qnorm(0.025, sm_state$alphahat[,1], (sqrt(sm_state$V[1,1,])))), \n                          p97.5_position = c(qnorm(0.975, sm_state$alphahat[,1],(sqrt(sm_state$V[1,1,])))), \n                          mean_position = (c(sm_state$alphahat[,1])),\n                          p2.5_growth_rate = c(qnorm(0.025, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                          p97.5_growth_rate = c(qnorm(0.975, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))),\n                          p25_growth_rate = c(qnorm(0.25, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                          p75_growth_rate = c(qnorm(0.75, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                          growth_rate = (c(sm_state$alphahat[,2])),\n                          percentile_0_growth_rate =c(pnorm(0, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))),\n                          dispersion=res$par[1], \n                          z_score_growth_rate = c(sm_state$alphahat[,2]/sqrt(sm_state$V[2,2,])))\n      } else if (series == \"new_deaths\"){\n        out <- data.frame(p2.5_signal_deaths = exp(qnorm(0.025, sm_signal$thetahat, sqrt(c(sm_signal$V_theta)))), \n                          p97.5_signal_deaths = exp(qnorm(0.975, sm_signal$thetahat, sqrt(c(sm_signal$V_theta)))), \n                          mean_signal_deaths = exp(sm_signal$thetahat), \n                          p2.5_position_deaths = c(qnorm(0.025, sm_state$alphahat[,1], (sqrt(sm_state$V[1,1,])))), \n                          p97.5_position_deaths = c(qnorm(0.975, sm_state$alphahat[,1],(sqrt(sm_state$V[1,1,])))), \n                          mean_position_deaths = (c(sm_state$alphahat[,1])),\n                          p2.5_growth_rate_deaths = c(qnorm(0.025, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                          p97.5_growth_rate_deaths = c(qnorm(0.975, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))),\n                          p25_growth_rate_deaths = c(qnorm(0.25, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                          p75_growth_rate_deaths = c(qnorm(0.75, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))), \n                          growth_rate_deaths = (c(sm_state$alphahat[,2])),\n                          percentile_0_growth_rate_deaths =c(pnorm(0, sm_state$alphahat[,2], (sqrt(sm_state$V[2,2,])))),\n                          dispersion_deaths=res$par[1], \n                          z_score_growth_rate_deaths = c(sm_state$alphahat[,2]/sqrt(sm_state$V[2,2,])))\n      }\n    } else {\n      if (series==\"new_confirmed\"){\n        sm_signal <- KFS(fit$model, filtering=\"signal\",smoothing='none')\n        sm_state <- KFS(fit$model, filtering=\"state\",smoothing='none')\n        \n        out <- data.frame(p2.5_position = c(qnorm(0.025, sm_state$a[-1,'level'], (sqrt(sm_state$P[1,1,-1])))), \n                          p97.5_position = c(qnorm(0.975, sm_state$a[-1,'level'],(sqrt(sm_state$P[1,1,-1])))), \n                          mean_position = (c(sm_state$a[-1,'level'])),\n                          p2.5_growth_rate = c(qnorm(0.025, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                          p97.5_growth_rate = c(qnorm(0.975, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))),\n                          p25_growth_rate = c(qnorm(0.25, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                          p75_growth_rate = c(qnorm(0.75, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                          growth_rate = (c(sm_state$a[-1,'trend'])),\n                          percentile_0_growth_rate =c(pnorm(0, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))),\n                          growth_rate = (c(sm_state$a[-1,'trend'])),\n                          dispersion=res$par[1], \n                          z_score_growth_rate = c(sm_state$a[-1,2]/sqrt(sm_state$P[2,2,-1])))\n      } else if (series == \"new_deaths\"){\n        \n        out <- data.frame(p2.5_position_deaths = c(qnorm(0.025, sm_state$a[-1,'level'], (sqrt(sm_state$P[1,1,-1])))), \n                          p97.5_position_deaths = c(qnorm(0.975, sm_state$a[-1,'level'],(sqrt(sm_state$P[1,1,-1])))), \n                          mean_position_deaths = (c(sm_state$a[-1,'level'])),\n                          p2.5_growth_rate_deaths = c(qnorm(0.025, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                          p97.5_growth_rate_deaths = c(qnorm(0.975, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))),\n                          p25_growth_rate_deaths = c(qnorm(0.25, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                          p75_growth_rate_deaths = c(qnorm(0.75, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))), \n                          growth_rate_deaths = (c(sm_state$a[-1,'trend'])),\n                          percentile_0_growth_rate_deaths =c(pnorm(0, sm_state$a[-1,'trend'], (sqrt(sm_state$P[2,2,-1])))),\n                          growth_rate_deaths = (c(sm_state$a[-1,'trend'])),\n                          dispersion_deaths=res$par[1], \n                          z_score_growth_rate_deaths = c(sm_state$a[-1,2]/sqrt(sm_state$P[2,2,-1])))\n      }\n    }\n    \n    if (any(grepl('administrative_area',colnames(dat)))){\n      if (any(out$p97.5_signal > 1e8)) return(cbind(d, error=\"97.5_signal > 1e8\"))\n    }\n    if (quantile(abs(out$z_score_growth_rate), probs=0.75) < 0.4) return(cbind(d, error=\"quantile(abs(out$z_score_growth_rate), probs=0.75) < 0.4\"))\n    \n    tack_on <- matrix(NA, nrow=nrow(dat), ncol=ncol(out)) %>% as.data.frame()\n    colnames(tack_on) <- colnames(out)\n    tack_on[pass,] <- out\n    return(cbind(dat, tack_on))\n  }\n}\n\n\ncovid19_nbss <- function(dat,series=\"new_confirmed\", level='all',\n                         mc.cores=1, precomputed_dispersions=NULL,\n                         filtering=FALSE){\n  if (level==\"country\"){\n    tmp <- filter(dat, administrative_area_level==1)\n  } else if (level==\"state\"){\n    tmp <- filter(dat, administrative_area_level==2)\n  } else if (level==\"all\") {\n    tmp <- dat\n  } else {\n    stop(\"only level variables that are supported are all, country, and state\")\n  }\n  tmp <- dat %>% \n    mutate(new_deaths = ifelse(new_deaths < 0, 0, new_deaths), \n           new_confirmed = ifelse(new_confirmed < 0, 0, new_confirmed)) %>% \n    as.data.frame() %>% \n    split(.$id)\n  if (mc.cores == 1){\n    fits <- list()\n    pb <- progress_bar$new(total = length(tmp), format=\" [:bar] :percent eta: :eta\")\n    for (i in 1:length(tmp)){\n      pb$tick()\n      fits[[i]] <- fit_covid_ssm(tmp[[i]], series, precomputed_dispersions,filtering=filtering)\n      #if (is.null(fits[[i]])) stop(\"foo\")\n    }  \n  } else {\n    cl <- parallel::makeCluster(mc.cores)\n    parallel::clusterEvalQ(cl, {\n      library(tidyverse)\n      library(lubridate)\n      library(KFAS)\n      library(tsoutliers)\n      library(data.table)\n    })\n    parallel::clusterExport(cl,c(\"custom_processors\", \"outlier_detection\", \"fit_covid_ssm\"))\n    fits <- parLapply(cl, tmp,  function(x,series,precomputed_dispersions,filtering) fit_covid_ssm(x, series, precomputed_dispersions,filtering=filtering),\n                      series=series,precomputed_dispersions=precomputed_dispersions,filtering=filtering)\n    stopCluster(cl)\n    rm('cl')\n  }\n  fits <- bind_rows(fits)\n  return(fits)\n}\n\n\ncustom_processors <- function(dat,pass){\n  # Iowa and Indiana\n  # if (unique(dat$administrative_area_level_2)%in%c(\"Iowa\", \"Indiana\", \"Kentucky\")){\n  \n  if (unique(dat$administrative_area_level_1)==\"United States\"){\n    if (!is.na(unique(dat$administrative_area_level_2))){\n      if (unique(dat$administrative_area_level_2 != \"Washington\")){\n        pass <- pass & (dat$date > ymd(\"2020-02-28\") )\n      }\n    }\n    # Insert new US custom processors here\n  }\n  return(pass)\n}\n\noutlier_detection <- function(x){\n  if (sum(x, na.rm=TRUE) < 100 &  sum(x==0, na.rm=TRUE) > length(x)*0.5){\n    return(x)\n  } else {\n    res <- NULL\n    tryCatch({\n      res <- tso(ts(x),\n                 type=\"TC\", delta=0.1, maxit.iloop = 100, maxit.oloop = 10,  \n                 #tsmethod = \"auto.arima\", args.tsmethod = list(allowdrift = FALSE, ic = \"bic\", stationary=TRUE),\n                 tsmethod=\"arima\", args.tsmethod=list(order=c(1,1,2), method=\"ML\", transform.pars=TRUE, optim.method=\"BFGS\"),\n                 cval=4)\n    }, error = function(err){\n      res <- tryCatch(tso(ts(x),\n                          type=\"TC\", delta=0.1, maxit.iloop = 100, maxit.oloop = 10, \n                          #tsmethod = \"auto.arima\", args.tsmethod = list(allowdrift = FALSE, ic = \"bic\", stationary=TRUE),\n                          tsmethod=\"arima\", args.tsmethod=list(order=c(1,1,2), method=\"ML\", transform.pars=FALSE),\n                          cval=4),error=function(e) NULL)\n    })\n    if (is.null(res)){\n      return(x)\n    } else {\n      res <- res$outliers %>% \n        filter(tstat > 10)\n      x[res$ind] <- NA\n      return(x)\n    }\n  }\n}\n\noutlier_detection_par <- function(x,id,cl){\n  dd <- data.frame('x'=x,'id'=id)\n  clusterExport(cl,'dd',envir = environment())\n  ids <- unique(id)\n  outdet <- function(id,dd.=dd) outlier_detection(dd$x[dd$id==id])\n  x <- parSapply(cl,ids,outdet) %>% unlist\n  return(x)\n}\n\n\nforecast <- function(nyc,uk){\n  nyc_time <- max(nyc$outbreak_time,na.rm=T)\n  max_time <- max(uk$outbreak_time,na.rm=T)\n  \n  ### need to update x from nyc_time+1 to max_time.\n  \n  ### To do so, we need to project NYC growth rates assuming a parallel trajectory to UK\n  ukk <- uk[outbreak_time>nyc_time,c('outbreak_time','growth_rate','p2.5_growth_rate','p97.5_growth_rate')]\n\n  fit <- gam(growth_rate~s(outbreak_time),data=ukk)\n  fit2.5 <- gam(p2.5_growth_rate~s(outbreak_time),data=ukk)\n  fit97.5 <- gam(p97.5_growth_rate~s(outbreak_time),data=ukk)\n  init <- nyc[.N,c('p2.5_growth_rate','growth_rate','p97.5_growth_rate','mean_position')]\n  \n  last <- data.frame('outbreak_time'=nyc_time)\n  dum <- nyc[1:(max_time-nyc_time)]\n  dum[,outbreak_time:=(nyc_time+1):max_time]\n  dum[,date:=max(nyc$date)+1:.N]\n  \n  ### predicting NYC growth rates: UK_gam - UK_intercept + NY_latest_value\n  \n  dum$growth_rate <- fit$fitted.values-c(predict(fit,newdata = last))+init$growth_rate\n  dum$p2.5_growth_rate <- fit2.5$fitted.values-c(predict(fit2.5,newdata=last))+init$p2.5_growth_rate\n  dum$p97.5_growth_rate <- fit97.5$fitted.values-c(predict(fit97.5,newdata=last))+init$p97.5_growth_rate\n  \n  dum$mean_position <- init$mean_position+cumsum(dum$growth_rate)\n  dum$p2.5_position <- init$mean_position+cumsum(dum$p2.5_growth_rate)\n  dum$p97.5_position <- init$mean_position+cumsum(dum$p97.5_growth_rate)\n  dum$rm <- NA\n  dum$new_confirmed <- NA\n  dum$raw_cases <- NA\n  dum$forecast <- TRUE\n  nyc$forecast <- FALSE\n  \n  dum <- rbind(nyc[.N],dum)\n  dum[1,p2.5_position:=mean_position]\n  dum[1,p97.5_position:=mean_position] \n  ## stitching together so the \"forecast\" includes the last observation and fans out.\n  ## This isn't exactly right, since our last observation's estimated mean position\n  ## may not be the true position, but we'll assume these errors in mean_position\n  ## are small relative to the propagated uncertainty in growth rates\n  \n  return(rbind(nyc,dum))\n}\n\n\nglue_ma <- function(nyc){\n  ix <- which(nyc$forecast)\n  x <- nyc$raw_cases\n  x[ix] <- exp(nyc[ix,mean_position]) ## Forecast exp(mean_position)\n  \n  rm <- nyc$rm\n  rm[ix] <- round(frollmean(x,7,align='right',na.rm=T))[ix]\n  nyc$rm <- rm\n  \n  rm2.5 <- rm\n  x[ix] <- round(exp(nyc[ix,p2.5_position])) ## replace forecasted observations with \n  rm2.5[ix] <- round(frollmean(x,7,align='right',na.rm=T))[ix]\n  nyc$p2.5_rm <- rm2.5\n  \n  \n  rm97.5 <- rm\n  x[ix] <- round(exp(nyc[ix,p97.5_position]))\n  rm97.5[ix] <- round(frollmean(x,7,align='right',na.rm=T))[ix]\n  nyc$p97.5_rm <- rm97.5\n  \n  return(nyc)\n}\n",
    "created" : 1649350169440.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3928911398",
    "id" : "6B91D1DE",
    "lastKnownWriteTime" : 1649368602,
    "last_content_update" : 1649368602147,
    "path" : "~/COVID/NYC_BA2_dashboard/scripts/utils.R",
    "project_path" : "scripts/utils.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}